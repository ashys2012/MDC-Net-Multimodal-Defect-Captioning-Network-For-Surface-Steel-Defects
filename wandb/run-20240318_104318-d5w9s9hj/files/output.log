Shape of self.encoder_pos_embed: torch.Size([1, 196, 512])
skipping pos_embed...
skipping pos_embed...
num_training_steps is: 9000
num_warmup_steps is: 900
Epoch 1/200
  0%|                                                                                                                                            | 0/45 [00:00<?, ?it/s]
BLEU Score: 0.0004429106611939321
the shape of predicted_bboxes is torch.Size([32, 1, 4])
the shape of ground_truth_bboxes is torch.Size([32, 8, 4])
Average IoU score: 0.0
THe giou_bbox_loss is tensor(1.4062)

  2%|█▉                                                                                     | 1/45 [00:02<02:02,  2.78s/it, iou_loss=1.41, lr=0.000000, train_loss=3.09]
BLEU Score: 0.0004055382417906339
the shape of predicted_bboxes is torch.Size([32, 1, 4])
the shape of ground_truth_bboxes is torch.Size([32, 4, 4])
Average IoU score: 0.0
THe giou_bbox_loss is tensor(1.2188)
  4%|███▊                                                                                   | 2/45 [00:04<01:40,  2.35s/it, iou_loss=1.31, lr=0.000000, train_loss=3.02]
Traceback (most recent call last):
  File "/mnt/sdb/2024/pix_2_seq_with_captions_march/trail_01.py", line 208, in <module>
    train_eval(model,
  File "/mnt/sdb/2024/pix_2_seq_with_captions_march/trail_01.py", line 166, in train_eval
    train_loss = train_epoch(model, train_loader, optimizer, lr_scheduler if step == 'batch' else None, criterion, logger = logger, iou_loss_weight=0.8)
  File "/mnt/sdb/2024/pix_2_seq_with_captions_march/train_val_epoch.py", line 58, in train_epoch
    tokens_caps_bbox = top_k_sampling(preds.reshape(-1, preds.size(-1)), k=5).reshape(preds.size(0), -1)
  File "/mnt/sdb/2024/pix_2_seq_with_captions_march/data_processing.py", line 588, in top_k_sampling
    return torch.multinomial(probs, 1)
KeyboardInterrupt