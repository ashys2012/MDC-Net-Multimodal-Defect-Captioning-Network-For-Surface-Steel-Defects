Shape of self.encoder_pos_embed: torch.Size([1, 196, 512])
skipping pos_embed...
skipping pos_embed...
num_training_steps is: 9000
num_warmup_steps is: 900
Epoch 1/200
  0%|                                                                                                                                            | 0/45 [00:00<?, ?it/s]
BLEU Score: 0.0004429106611939321
---------#################################---------------------
Average IoU score: nan
THe giou_bbox_loss is tensor(1.4062)

  2%|█▉                                                                                     | 1/45 [00:02<02:01,  2.75s/it, iou_loss=1.41, lr=0.000000, train_loss=3.09]
BLEU Score: 0.0004055382417906339
---------#################################---------------------
Average IoU score: nan
THe giou_bbox_loss is tensor(1.2188)
THe giou_bbox_score is [tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([]), tensor([])]
BLEU Score: 0
---------#################################---------------------
Average IoU score: nan
THe giou_bbox_loss is tensor(1.2500)

  4%|███▊                                                                                   | 2/45 [00:04<01:31,  2.13s/it, iou_loss=1.31, lr=0.000000, train_loss=3.02]
BLEU Score: 0.0002299884818003046
---------#################################---------------------
Average IoU score: nan
THe giou_bbox_loss is tensor(1.1250)
  7%|██████                                                                                    | 3/45 [00:07<01:40,  2.38s/it, iou_loss=1.29, lr=0.000000, train_loss=3]
Traceback (most recent call last):
  File "/mnt/sdb/2024/pix_2_seq_with_captions_march/trail_01.py", line 208, in <module>
    train_eval(model,
  File "/mnt/sdb/2024/pix_2_seq_with_captions_march/trail_01.py", line 166, in train_eval
    train_loss = train_epoch(model, train_loader, optimizer, lr_scheduler if step == 'batch' else None, criterion, logger = None, iou_loss_weight=0.8)
  File "/mnt/sdb/2024/pix_2_seq_with_captions_march/train_val_epoch.py", line 124, in train_epoch
    _, gt_bboxes, _ = extract_ground_truth(y_expected_adjusted, tokenizer)  # You need to implement this based on your dataset
  File "/mnt/sdb/2024/pix_2_seq_with_captions_march/iou_bbox.py", line 137, in extract_ground_truth
    labels, bboxes, caption = tokenizer.decode(tokens)
  File "/mnt/sdb/2024/pix_2_seq_with_captions_march/data_processing.py", line 339, in decode
    eoc_idxs = (tokens == self.CAPTION_END).nonzero(as_tuple=True)[0]
KeyboardInterrupt